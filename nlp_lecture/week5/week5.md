### 챗봇~??

#### 키워드(명사), 인텐트(말의 의도)

키워드 -> NER(개채명 인식) 

인텐트 -> intent classification



cf. CRF : 개체명인식기에서 LSTM의 성능을 올리기 위한 것

2d convolution 연산에는 가중치(3x3 커널)가 있고 (처음엔 랜덤초기화) 

2d max-pooling 연산에는 없음

-> 2개를 조합하여 쌓음



1d convolution 의 커널사이즈(커널사이즈 2다, 3이다 이렇게 부름)는 n-gram의 n과 같음

![image-20210822102112026](C:\Users\1231d\AppData\Roaming\Typora\typora-user-images\image-20210822102112026.png)

conv1D에도 편향 1개씩 붙어잇음 = 총 파라미터 96개

dense 파라미터에도 편향 1개씩 부터잇음 = 12 + 2 = 14개



####  char-level 1d convolution 

=alphabet level

단어를 벡터로 만든다.



q1. 이진분류인데 sigmoid 사용할 수 없나요~?

이진분류인데 클래스 2개이니까 softmax쓰는거~!

#### RNN

![image-20210822103536048](C:\Users\1231d\AppData\Roaming\Typora\typora-user-images\image-20210822103536048.png)



#### many-to-many RNN

입력에 대해 출력을 항상함.

모든 step에 대해 항상 라벨링을 함.

(뒤에서 자세히 설명!)



q2. 

1) LSTM에서 첫번째 샘플, 두번째 샘플의 
   timestamp1시점 h_t-1 (이전 은닉층 값)는 어떻게 정해지나요??

단순히 초기화 해서 시작됨. 과거 없을때는 initial state 초기화된 값을 가지고 시작됨.

2. many-to-many문제에서 LSTM으로 여러 은닉층을 쌓게 되면, 
다음 층의 입력값으로 이전층 hidden state와 cell state를 모두 사용하나요~??

LSTM은 hidden state뿐만아니라 cell state가 또 있는데, 오른쪽으로 두개 다 보내고

다음층 (위층)으로 보낼때는 hidden state만 보냄.



q3.

저번 주 코드에서 input_length = time_step 라고 하셨는데, 왜 time_step이 파라미터 값에 영향을 주지 않는지 이해를 잘 못했어요. Wx나 xt의 크기가 time_step(d)의 영향을 받는 것 아닌가요?

wh, wx는 입력벡터와 hidden state 벡터를 주는 순간 결정이 됨.  다만 랜덤초기화 된 상태이고.

계산하는동안 영향을 주진 않음. 문장길이랑 wh, wx는 관련이 없음.



q4. wh , wx의 크기가 바뀌지 않는 이유가 패딩을 해서인가?

아닙니다. 상관없음!



q5. 혹시 두번째샘플부터도 timestamp1시점 hidden state도 초기화되어있고 
이전 샘플학습 때의 마지막 hidden state에서 받아오지는 않나요??

패딩은 병렬처리를 위해 하는 것이다.

데이터 5만개 있을때 문장의 길이가 대체적으로 다를 것이다. 패딩을하여 문장의 길이를 맞춰놓고

64개씩 병렬로 펼쳐놓고 

저는 좋은 학생 입니다 <pad> : 5

제 이름은 샘 입니다 : 5

batch_size = 2

rnn은 동시에 연산을 함.



#### 개체명 인식

Sequence Labeling 

개체명 인식은 시퀀스 레이블링 태스크에 속함.

so, 입력과 레이블의 길이가 같아야 함.

```return_sequences=True``` 항상 output을 낸다. 모든 timesteps에 대해 예측한다.

정의 : 주요한 명사에 대해 뭔가에 대해 어떤 개체인가 알려주고 싶을때!



#### BIO Tagging (Begin, Inside, Outside)

해리포터보러가자

(B I I I O O O O)

해(B-movie)

리

포

터

보

러

메(B-theater)

가

박

스

가

자

#### CRF

BiLSTM나오기 전에 사용되던 시퀀스 레이블링 모델 (개체명 인식을 학습시켜서 할 수 있었다.)

#### BiLSTM + CRF 

BiLSTM위에 CRF를 얹음.

전체적으로 경우의 수를 조합해서 예측하는것!!

굳이 CRF를 왜하느냐??

-> 일반적인 BiLSTM모델은 각 단어를 벡터로 입력받고 출력층에서 활성화 함수를 통해 개체명 예측

-> 개체명 두개면 5개로 레이블링 가능 (B-per, I-per, B-org, I-org, O)

-> 제대로 예측하는 거 앎? 몰라요... 현재 입력단어 전체가 어떤단어인지 보여주지 않으므로 알수 없음

-> BIO 규칙 위반한것은 알 수 있음! I-xx는 반드시 B-xx뒤에 등장., O뒤에는 I가 등장할 수 없다.

-> CRF를 얹었더니 BIO 규칙 자체를 학습하는 계기가 되어서 규칙 위반을 보정하는 효과가 있었다!



q6. input이 char 인가요 단어 인가요?

input은 char이 될수도 있지만 일반적으로는 단어를 입력함.

ex) 도날드 트럼프 (B-per, I-per)



#### Bi-LSTM + CNN (성능을 좀 더 높일 수 잇다!!!)

워드임베딩이랑 같이 ```CNN-extracted Char Features``` 입력을 넣어줌.

단어에 대해 char CNN을 돌려서 벡터값을 뽑아냄.

https://wikidocs.net/116193

커널에 대해 1d convolution하고 max-pooling한 벡터값.

#### 왜 주는건가염~??

ex) 

apple => apple이라는 임베딩 벡터값

apples => UNK

이 두가지의 값은 전혀 다름.

-----------------

apple => 1D char CNN을 얻은 벡터값

apple => 1D char CNN을 얻은 벡터값

이 두가지의 값은 유사함. 

철자가 비슷하면 비슷한 벡터값을 갖게됨.

----

∴ 결과적으로 유사한 단어를 구분할 수 있게함.

q7.  LSTM 인풋으로 '워드임베딩벡터'랑 '캐릭터CNN 벡터' 두 개가 입력인가요??
아니면 이 두개의 벡터를 concatenate해줘서 하나의 입력으로 사용하나요??

concatenate 해줍니다! 코드 설명드릴때 보실 수 있을거에요 ㅎㅎ



#### 개체명 인식 할 때 참고할것!!

2018년 12월 naver 개체명 인식 대회!

하지만 대회용이지 현업에 사용할 수 없음

형태소 분석 토큰화된게 아님 ㄷㄷ



#### F1 score

성능 측정할 때 accuracy를 썼는데 (퍼센티지)

쓰면 안되는 경우가 있음 : 함정이 있기 때문임!!!!

ex) 코로나 진단키트 

/ 100명중에 2명이 양성

/ 키트는 모두 음성으로 진단.

=> 정확도가 98% 사실 아예 못맞춘건뎅..?ㅎㅎ

ex2) 스팸메일 분류

=> 정확도가 90%나 된다!

=> 정상 메일이 90% 스팸메일이 10% 인경우에도 정확도가 90% ? ㅋㅋㅋ



*** 특정 레이블이 불균형할 때!!!! accuracy의 함정에 빠질 수 있다. ***



F1 score를 사용하면 높은 값이 나오지 않음!

계산하는 패키지가 많음!



#### 개체명인식 2 코드 설명

레이블도 토커나이징, 패딩 다 함,,,, 입려과 레이블 길이가 같으니까 ㅋ



- BiLSTM - CNN 할때 추가 전처리가 필요! -> 각 단어를 alphabet 단위로 다 쪼갬.
- X_data[0] : word embedding
- X_char_data[0] : char embedding



q8. 어디까지가 단어인지 어디부터 char embedding인지 어떤 원리로 인식하나요?

파라미터를 [x_train, x_char_train] 이런식으로 각각 넣어주면 분기가 됨.

q9. concatenate 이후에는 구별이 상관이 없나요?

네. 어차피 오차를 줄이려고 하는 거기 때문에 상관없음. 숫자들의 나열일 뿐.

q10. 글자임베딩 한글에서도 되나요?

넵 됩니다.



### Intent Classification

이진분류

sigmoid -> Dense(1, activation='sigmoid')

softmax -> Dense(2, activation='softmax')



#### 챗봇에 응용한다면?

잘못된 분류 -> 데이터셋이 충분하지 않았음.

새로운 데이터 추가해주면 됨. (수작업으로 추가해주는게 좋음 ㅋㅋㅋ)



q11. 데이터 학습 할 때 . ? 같은 부호는 제외하나요?

없앨 필요는 없고 형태소 분석에서 자동으로 제외됨.



q12. 보여주신 챗봇 구조 간단히

개체 모델 따로

의도 모델 따로



의도 분류 모델을 분류 함 -> 분류에 맞는 함수로 -> 답변 보냄 

ex) 날씨에 대한 챗봇이라면~?

구현된 함수에 개체명 모델을 돌렸을 때 나온 개체명으로 답변을 준비해서 보냄.

개체명 없는 경우에 대한 처리도 되어있어야 함.



기획을 쫌 빡세게 하는게 좋구요 ㅋㅋㅋㅋㅋㅋㅋ ㅎㅎㅎ킬포 ,, !!!! 넘나 공감



q13. 경우의 수가 많을 수록 사용자가 느끼는 성능이 높을 수 있겠네여..

그쳐 그리고.....

데이터가 절대적으로 많아야됨!!!!!



후 하 후 ㅎ ㅏ

q14. 보여주신 Python으로 구현한 모델로 챗봇UI(윈도우 어플리케이션?)는 어떻게 프로그래밍 되었나요?

웹개발의 영역 - ui는 doc2vec 챗봇만들기 영상 참고하심



q15. 그러면 서비스 하면서 추후에 사용자들이 입력하는 질문도 수집하면서 유지보수(?) 하는건가여?

실제로 그렇게 하면 좋음.

팁 ) 사용자 입력을 수집해서 데이터로 쓰는거죠... -> 사람이 검수..,..ㅋㅋㅋㅋ

휴먼러닝ㅋㅋㅋㅋㅋ



q16. 원천데이터 어떻게 만드나요?

가장 좋은 것은 사람이 만드는것이 좋음...











