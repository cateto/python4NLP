#### 메캅 : 설치방법 다 다름 / 다국어 토크나이저 -> 다국어라기ㄷ보다는 일정 기준으로 분리하는것

#### 다섯가지 한국어 토크나이저는 제공하는 함수명이 같다

- morphs가 일반적으로 가장많이 쓰는 추출방법

- nouns 워드클라우드 쓸때

- pos *품사가 다른 경우에 사용됨* ex) 못(noun), 못(adverb)

#### tpu코드를 따로 작성해야하나 : yes

#### pykospacing : 딥러닝 기반 구현되어잇어서 텐서플로랑 케라스 필요

#### ✨✨ 한국어 텍스트 : 형태소 분석 - > 불용어 제거 의 순서로 이루어져야함 ✨✨

#### stemming : 규칙 기반 / 섬세하지않더라도 단어 통일의 효과만 있으면 됨

### Q1. 형태소 분석 이전에 띄어쓰기 및 맞춤법 체크가이루어져야하나요? 
- > 명백하게 잘못된 데이터가 많을때 ex) 챗봇 -> 사람의 입력이 잘못됨(아무렇게나 던질때) -> 맞춤법 체크 후 형태소 분석이 이루어지면 좋을 것이다. ex2) 뉴스데이터 -> 이미 잘 지켜져 있기 때문에 안해도됨 , 전처리 시간만 늘리는 경우가 될수있으므로 상황에 맞게 주의하여 체크

### Q2. 영어와 한국어가 섞여 있는 경우, 어떻게 처리하나요?

- 다국어 -> 영어 띄어쓰기로, 한국어 형태소 분석 이루어짐.

### Q3. 제가 원하는대로 토큰화나 정규화가 안될때, NLTK 등의 모델들을 제가 원하는대로 쉽게 튜닝하는것이 가능한가요? 

- 모델을 직접 수정하기보다 전처리 후처리 함수를 수정하는것이 좀 더 제안되는 방법임

#### okt에만 잇는 stemming, normalization -> norm=True 조건!! 반복되는문자열 잘 분리해줌

#### 한국어 전처리 : 완성형문자만쓸것인지(가-힣) , 초성 중성 포함시키것인지 잘 정하기!

#### 영어 불용어 : 행위, 감정을 나타내는 것은 불용어에 포함이안됨 —— 단어 토큰화 이후에 결정 ——

#### 뉴스기사 일때 불용어 리스트 -> 무단배포 금지,,, 등등~~ 데이터마다 불용어가 달라짐 직접 정의를 할 수 밖에 없음

### Q4. 한글 불용어 리스트는 그럼 데이터가 어떻게 나오는지 확인하고 직접 선정하는 방법 밖에는 없나요?

- 미리 정의된것이 있지만 사용안하는게 좋은,,, 느끰 

### Q5. 토큰화가 된 상태 -> 각 단어에 고유한 정수 부여 why ?? 
딥러닝 수학적 계산 = 행렬 계산을 함

### Q6. 혹시 문장이 추가되어서 빈도순위가 변경하게되면 일반적으로 vocab을 자주 변경시키기도 하나요? 아니면 vocab은 한번 만들면 잘 변경하진 않는편인가요? 재학습시키거나..!

#### 케라스토크나이저에서 oov 사용하기로 하면 unk =1 번이됨

#### 패딩 앞으로 하느냐 뒤로 하느냐 모델에 따라, 논문에 따라 다름

### Q7. 원핫인코딩, 인티져인코딩 어떨떄 쓰는지? 

- 인티저인코딩 : 딥러닝 모델에 사용 (입력으로 입력) / 원핫인코딩 : 어떤 task, 어떤 특정 모델에 학습할 때 필요한 경우가 있음 / 인티저인코딩이나 , 패딩은 항상 똑같음