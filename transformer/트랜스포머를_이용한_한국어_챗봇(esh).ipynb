{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "트랜스포머를 이용한 한국어 챗봇(esh)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqDLubbFor0m"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SrR6OJqkOexI",
        "outputId": "3ccc660e-5219-49ef-8540-13c41d595b0f"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRMeKtGkpWyj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "2e76aaef-6d53-4717-96c9-1fc09cdbef81"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
        "\n",
        "train_data = pd.read_csv('ChatBotData.csv')\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn8U3VtpZM8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c4e859-0c94-4fc6-c12a-a3a27aeb2743"
      },
      "source": [
        "print('챗봇 샘플의 개수 :', len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "챗봇 샘플의 개수 : 11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnob5p7MZjb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8311ce74-bd61-4dcb-9030-5cda98e464a8"
      },
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q        0\n",
            "A        0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW1pjPZtpdHk"
      },
      "source": [
        "# References\n",
        "# https://github.com/changwookjun/learningspoons/blob/master/Day7_2_Transformer_advance_pb.ipynb\n",
        "# https://github.com/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb\n",
        "# https://www.tensorflow.org/tutorials/text/transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e7uRCzkbcn_"
      },
      "source": [
        "- 토큰화를 하기 위해 형태소 분석기를 사용하지 않기 때문에 구두점들을 미리 처리해준다\n",
        "- 단순 구두점 제거가 아닌 공백을 추가하여 다른 문자들과 구분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rVKq614riHj"
      },
      "source": [
        "questions = []\n",
        "for sentence in train_data['Q']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7qhEy1gbMtb"
      },
      "source": [
        "answers = []\n",
        "for sentence in train_data['A']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWOhJCaeaO0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8776a48-54b5-4a6c-f30b-e3f1ca1f3db8"
      },
      "source": [
        "len(questions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11823"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzcAUBSlaTOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80369818-d30e-4847-b982-d03db6db0e87"
      },
      "source": [
        "questions[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMZt4sNtaiZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86be4cab-a0e7-4187-ddd3-ed0d98a226b8"
      },
      "source": [
        "answers[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNSBFxyUiukK"
      },
      "source": [
        "인코더-디코더 모델 계열에는 디코더의 입력으로 사용할 시작을 의미하는 시작 토큰 SOS와 종료 토큰 EOS들도 단어 집합에 포함시킬 필요가 있으므로 이 두 토큰에 정수를 부여해준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmvgJ841bTzh"
      },
      "source": [
        "# 서브워드텍스트인코더를 사용하여 질문과 답변을 모두 포함한 단어 집합(Vocabulary) 생성\n",
        "# tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    #questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "    \n",
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W9W26OIbcs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8abeb2-2e0d-495b-e808-5eb2fb8bbf4f"
      },
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sample question: [5766, 611, 3509, 141, 685, 3747, 849]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaCSBZnIbwuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020b50fb-123b-42fb-f7c8-aa56fd10e835"
      },
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()와 decode() 테스트해보기\n",
        "\n",
        "# 임의의 입력 문장을 sample_string에 저장\n",
        "sample_string = questions[20]\n",
        "\n",
        "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
            "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q2Wn-R1Wk9J"
      },
      "source": [
        "각 정수와 맵핑되는 단어들"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y0QT-4YcAqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f12257-8301-48eb-a4ee-44a9f8402cb5"
      },
      "source": [
        "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
        "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5766 ----> 가스\n",
            "611 ----> 비 \n",
            "3509 ----> 비싼\n",
            "141 ----> 데 \n",
            "685 ----> 감기 \n",
            "3747 ----> 걸리\n",
            "849 ----> 겠어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjoGFbTONdTU"
      },
      "source": [
        "전체 데이터에 대해 정수 인코딩과 패딩 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrhb-b8ubfRn"
      },
      "source": [
        "# 최대 길이를 40으로 정의\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLX4l18TIqEZ"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DGwySwBciH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e432d0de-91f3-47ff-a4d8-d939ece59952"
      },
      "source": [
        "print('질문 데이터의 크기(shape) :', questions.shape)\n",
        "print('답변 데이터의 크기(shape) :', answers.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 데이터의 크기(shape) : (11823, 40)\n",
            "답변 데이터의 크기(shape) : (11823, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onyu0BWvI3D7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3134c6af-cacd-49ea-c0f3-aacc79fcfe86"
      },
      "source": [
        "# 0번째 샘플을 임의로 출력\n",
        "print(questions[0])\n",
        "print(answers[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_a1oU8caPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e36f3e3-5046-4525-b0bc-3dd6dfb567cb"
      },
      "source": [
        "print('단어 집합의 크기(Vocab size): {}'.format(VOCAB_SIZE))\n",
        "print('전체 샘플의 수(Number of samples): {}'.format(len(questions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기(Vocab size): 8180\n",
            "전체 샘플의 수(Number of samples): 11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CffgQvdCcgJn"
      },
      "source": [
        "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1q62D6dmXc6"
      },
      "source": [
        "tf.data.Dataset을 통해서 데이터를 배치 단위(병렬 연산 단위). 여기서는 64개로 묶고,\n",
        "데이터의 순서를 섞어주는 셔플 역할을 해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejvWp1B_JicQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ad0f35-1a6c-42d0-b94e-e1e445e0d6c5"
      },
      "source": [
        "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
        "print(answers[0]) # 기존 샘플\n",
        "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
        "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3siszyfdeyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308d280c-375d-4a04-ee17-c474039c0c0e"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2 #6\n",
        "D_MODEL = 256 #512\n",
        "NUM_HEADS = 8 #8\n",
        "UNITS = 512 #2048 dff의 크기\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8180, 256)\n",
            "(1, 8180, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwtbl-Bkdhhh"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIKeRf8tor41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6450417-1f6d-4423-94c1-0d50acff3b00"
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "185/185 [==============================] - 32s 118ms/step - loss: 1.4488 - accuracy: 0.0287\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 1.1719 - accuracy: 0.0494\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 1.0020 - accuracy: 0.0507\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.9289 - accuracy: 0.0544\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.8711 - accuracy: 0.0577\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.8125 - accuracy: 0.0616\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.7487 - accuracy: 0.0670\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.6770 - accuracy: 0.0747\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.5977 - accuracy: 0.0835\n",
            "Epoch 10/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.5152 - accuracy: 0.0928\n",
            "Epoch 11/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.4310 - accuracy: 0.1030\n",
            "Epoch 12/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.3492 - accuracy: 0.1143\n",
            "Epoch 13/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.2725 - accuracy: 0.1254\n",
            "Epoch 14/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.2076 - accuracy: 0.1358\n",
            "Epoch 15/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.1525 - accuracy: 0.1451\n",
            "Epoch 16/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.1093 - accuracy: 0.1531\n",
            "Epoch 17/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0799 - accuracy: 0.1585\n",
            "Epoch 18/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0608 - accuracy: 0.1619\n",
            "Epoch 19/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0505 - accuracy: 0.1638\n",
            "Epoch 20/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0443 - accuracy: 0.1647\n",
            "Epoch 21/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0416 - accuracy: 0.1650\n",
            "Epoch 22/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0397 - accuracy: 0.1654\n",
            "Epoch 23/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0361 - accuracy: 0.1661\n",
            "Epoch 24/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0305 - accuracy: 0.1675\n",
            "Epoch 25/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0278 - accuracy: 0.1682\n",
            "Epoch 26/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0241 - accuracy: 0.1690\n",
            "Epoch 27/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0216 - accuracy: 0.1697\n",
            "Epoch 28/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0197 - accuracy: 0.1702\n",
            "Epoch 29/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0176 - accuracy: 0.1708\n",
            "Epoch 30/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0162 - accuracy: 0.1711\n",
            "Epoch 31/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0145 - accuracy: 0.1716\n",
            "Epoch 32/50\n",
            "185/185 [==============================] - 22s 116ms/step - loss: 0.0143 - accuracy: 0.1716\n",
            "Epoch 33/50\n",
            "185/185 [==============================] - 22s 116ms/step - loss: 0.0128 - accuracy: 0.1719\n",
            "Epoch 34/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0115 - accuracy: 0.1723\n",
            "Epoch 35/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0115 - accuracy: 0.1723\n",
            "Epoch 36/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0105 - accuracy: 0.1726\n",
            "Epoch 37/50\n",
            "185/185 [==============================] - 22s 116ms/step - loss: 0.0097 - accuracy: 0.1727\n",
            "Epoch 38/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0097 - accuracy: 0.1727\n",
            "Epoch 39/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0092 - accuracy: 0.1730\n",
            "Epoch 40/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0085 - accuracy: 0.1730\n",
            "Epoch 41/50\n",
            "185/185 [==============================] - 22s 116ms/step - loss: 0.0079 - accuracy: 0.1732\n",
            "Epoch 42/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0074 - accuracy: 0.1733\n",
            "Epoch 43/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0075 - accuracy: 0.1733\n",
            "Epoch 44/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0072 - accuracy: 0.1734\n",
            "Epoch 45/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0073 - accuracy: 0.1734\n",
            "Epoch 46/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0064 - accuracy: 0.1736\n",
            "Epoch 47/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0059 - accuracy: 0.1737\n",
            "Epoch 48/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0058 - accuracy: 0.1737\n",
            "Epoch 49/50\n",
            "185/185 [==============================] - 22s 118ms/step - loss: 0.0056 - accuracy: 0.1738\n",
            "Epoch 50/50\n",
            "185/185 [==============================] - 22s 117ms/step - loss: 0.0059 - accuracy: 0.1736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0394db590>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzWLLIbY6GWL"
      },
      "source": [
        "model.save_weights('mnist_mlp_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS-DgXEsdmy0"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
        "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt1I1uIbZa3J"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbvBdX_5ovOM"
      },
      "source": [
        "# 아래는 에포크 50을 돌린 후의 결과임"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdzi13gDowJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b7efac-f604-4626-9830-d5d1257d30e1"
      },
      "source": [
        "output = predict('영화 볼래?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 영화 볼래?\n",
            "Output: 직접 확인해보세요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaVRIbbYoyQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e65eaf-5177-4c61-c4bb-c05af2cb31c9"
      },
      "source": [
        "output = predict(\"고민이 있어\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 고민이 있어\n",
            "Output: 제가 고민을 들어드릴게요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nOpxx0pozKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7198631-9bf2-433e-faf7-1dec659cb78d"
      },
      "source": [
        "output = predict(\"너무 화가나\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 너무 화가나\n",
            "Output: 그럴수록 당신이 힘들 거예요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuJJ9U_Yo0qN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb3692e-c030-46cd-8e38-acbaa33b726d"
      },
      "source": [
        "output = predict(\"카페갈래?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 카페갈래?\n",
            "Output: 카페 데이트 좋죠 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-7arrKIo2DR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d227718-5c8a-477c-cb95-0b09f92763c6"
      },
      "source": [
        "output = predict(\"게임하고싶당\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 게임하고싶당\n",
            "Output: 그럴 때가 있어요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmlHh28rVrD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6d305b-1bec-4fde-b6e6-cf2e405508ee"
      },
      "source": [
        "output = predict(\"게임하자\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 게임하자\n",
            "Output: 게임하세요 !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ-WJR8y6i88",
        "outputId": "d1a1c69a-bd77-4e81-d9fa-5d0cd6373074"
      },
      "source": [
        "output = predict(\"저 질문 있어요\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 저 질문 있어요\n",
            "Output: 직접 물어보세요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqxy4T8_6pwu",
        "outputId": "efaf0c22-5bc8-434d-e85e-449d821049cd"
      },
      "source": [
        "output = predict(\"서울역 어떻게 가요?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 서울역 어떻게 가요?\n",
            "Output: 마음이 많이 힘든가봅니다 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM1VueMo6tgO",
        "outputId": "6793fad0-e235-43f9-b61a-6bbd4900f0c3"
      },
      "source": [
        "output = predict(\"저 가방 너무 갖고싶어\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 저 가방 너무 갖고싶어\n",
            "Output: 한 잔하기 좋은 날이네요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtyE42xX6ycm",
        "outputId": "7b2819cd-1425-4fc9-d5d4-8b45bd3063e6"
      },
      "source": [
        "output = predict(\"내일 만날래?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 내일 만날래?\n",
            "Output: 많이 그리운가봐요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaVRciQQFaSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4b7eae-676e-4226-91ff-8d668abbbd16"
      },
      "source": [
        "output = predict(\"어제 뭐했어?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 어제 뭐했어?\n",
            "Output: 커피향 입고 눅눅눅눅눅눅눅눅눅눅커피향 커피향 눅눅눅눅눅눅커피향 커피향 커피향 커피향 커피향 커피향 운명적인 돌리는 운명적인 운명적인 운명적인 운명적인 돌리는 운명적인 돌리는 운명적인 치는 치는 커피향 커피향 \n"
          ]
        }
      ]
    }
  ]
}