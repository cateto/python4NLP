{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_model_success_to_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sxiIqH3_nIwX9uvXbPlml4fy50JaHkVC",
      "authorship_tag": "ABX9TyPx0qq6233ktd0mBVLO8K0a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "072fef589c6b49f781856246e0aabcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88ca472fa11e4dd7bec10f9b2df6a1ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46addf17c0a94ac2815437d4532fd5ae",
              "IPY_MODEL_b2c8459ee5c34afa8491b4d69c8332a4"
            ]
          }
        },
        "88ca472fa11e4dd7bec10f9b2df6a1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46addf17c0a94ac2815437d4532fd5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94fdb999fb4541db8466470a19cf726f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e9f158a683a4a2ab5d5d65a3903531b"
          }
        },
        "b2c8459ee5c34afa8491b4d69c8332a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06de1cdafb9941f692868e6365c5f307",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 300/300 [02:22&lt;00:00,  2.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9633c94493f64bfdb4c2ec764bd5788e"
          }
        },
        "94fdb999fb4541db8466470a19cf726f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e9f158a683a4a2ab5d5d65a3903531b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06de1cdafb9941f692868e6365c5f307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9633c94493f64bfdb4c2ec764bd5788e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1a81b7963c1435e8008775396983e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d227fdae3e74bc28c48203fa974740c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_247169777fbf4fbd89cb937d22c0a040",
              "IPY_MODEL_d01175cfd1c249abb6a3f318e9d5d0dd"
            ]
          }
        },
        "4d227fdae3e74bc28c48203fa974740c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "247169777fbf4fbd89cb937d22c0a040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69f2240572db4bceaa364a01ab373b5d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5107488c37d46579fc9f6b3a531e171"
          }
        },
        "d01175cfd1c249abb6a3f318e9d5d0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1b1f11c0e6748009b090d8daea99b0c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 300/300 [02:21&lt;00:00,  2.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0fe8cc9b60a43cb800e6467612681ba"
          }
        },
        "69f2240572db4bceaa364a01ab373b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5107488c37d46579fc9f6b3a531e171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1b1f11c0e6748009b090d8daea99b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0fe8cc9b60a43cb800e6467612681ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cateto/python4NLP/blob/main/kobert/load_model_success_to_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3V7hMPqeRRr",
        "outputId": "c5aa816c-7b37-45be-f263-3df2962e8816"
      },
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "# 변경: 최신 버전으로 설치하면 \"Input: must be Tensor, not str\" 라는 에러 발생\n",
        "!pip install transformers==3\n",
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 43 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 16.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595738 sha256=e5de3e0fdbcd1ed3076771bf6ca2ee7dc723f781c40957d689f2793bdd027012\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 22.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers==3\n",
            "  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n",
            "\u001b[K     |████████████████████████████████| 754 kB 27.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 64.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.0-rc4\n",
            "  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.8.0rc4 transformers-3.0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ATgH7x5eUXE",
        "outputId": "b2695dab-1588-4cea-9637-778acef9864d"
      },
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-u169t1i3\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-u169t1i3\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12770 sha256=59a9d4f7f6fa196a4717a10a45c2b003a902f0d4dbd96a5063e2fc5a9382b087\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yc3pbv30/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEHL-ZpeWi7"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdQZAQV36oEF"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eKaYuVjd3t2"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768, # bert의 hidden layer 크기?\n",
        "                #  num_classes=2,\n",
        "                 num_classes=9, # 분류 class 크기\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes) #nn.Linear\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDH8G58PehSk"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZS9up3rgX36"
      },
      "source": [
        "class NewsPredict():\n",
        "\n",
        "  def __init__(self, device_type='cpu'):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "          device_type : default는 \"cpu\", gpu로 돌리고자 할 때 \"cuda:0\"을 입력합니다.\n",
        "    \"\"\"\n",
        "    self.device = torch.device(device_type) # cpu로 돌리도록 선언 기본값 / \"cuda:0\"\n",
        "    self.max_len = 128 # seqeunce 최대 길이\n",
        "  \n",
        "  #model and tokenizer 로딩 \n",
        "  def load_model_n_tokenizer(self, model_path):\n",
        "    \"\"\"\n",
        "      tips: Pytorch Model과 Tokenizer를 반환합니다.\n",
        "      Args:\n",
        "          model_path : 모델이 저장된 path.\n",
        "      Returns:\n",
        "          tok : nlp.data.BERTSPTokenizer\n",
        "          model : torch model\n",
        "    \"\"\"\n",
        "    bertmodel, vocab = get_pytorch_kobert_model()\n",
        "    tokenizer = get_tokenizer()\n",
        "    tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "    \n",
        "    model = torch.load(model_path, map_location=self.device)\n",
        "\n",
        "    return tok, model\n",
        "\n",
        "  #전처리 안된 데이터 전처리\n",
        "  def preprocess_data(self, data_path, data_colname):\n",
        "    \"\"\"\n",
        "      tips: csv 데이터를 받아 지정된 column의 내용을 preprocess 합니다.\n",
        "      Args:\n",
        "          data_path : csv데이터의 path\n",
        "          data_colname : 지정할 column명\n",
        "      Returns:\n",
        "          lucy_data : DataFrame\n",
        "    \"\"\"\n",
        "    lucy_data = pd.read_csv(data_path)\n",
        "\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"\\(.*\\)|\\s-\\s.*\",\" \" ,regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"\\[.*\\]|\\s-\\s.*\",\" \",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"\\<.*\\>|\\s-\\s.*\",\" \",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"무단전재 및 재배포 금지\",\" \",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"무단 전재 및 재배포 금지\",\" \",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"©\",\" \",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"ⓒ\",\" \",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"저작권자\",\" \",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\".* 기자\", \" \", regex=True) #기자 이름에서 오는 유사도 차단\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"사진 = .*\", \" \", regex=True) #사진 첨부 문구 삭제\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"사진=.*\", \" \", regex=True) #사진 첨부 문구 삭제\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace('\\\"', \"\",regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+)\", \" \", regex=True) #이메일 주소에서 오는 유사도 차단\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"\\n\",\" \")\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"\\r\",\" \")\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"\\t\",\" \")\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace( \"\\’\" , \"\", regex=True)\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\" \")\n",
        "    lucy_data[data_colname] = lucy_data[data_colname].str.replace(\"[ ]{2,}\",\" \",regex=True)\n",
        "    \n",
        "    return lucy_data\n",
        "\n",
        "  #라벨을 정수로 인코딩\n",
        "  def category_encoding_n_save(self, lucy_data, save_directory, label_colname):\n",
        "    \"\"\"\n",
        "      tips: 텍스트로 된 라벨을 model에 지정된 정수 label로 인코딩 및 model의 input data를 파일로 저장합니다.\n",
        "      Args:\n",
        "          lucy_data : dataframe 형식의 데이터\n",
        "          save_directory : 저장할 디렉토리(파일명은 제외)\n",
        "          label_colname : 라벨의 컬럼명\n",
        "      Returns:\n",
        "          save_path : string\n",
        "    \"\"\"\n",
        "    lucy_data[label_colname+'_val'] = lucy_data[label_colname] # string 형 컬럼 생성\n",
        "\n",
        "    label_dict = {'0': 'IT/과학',\n",
        "      '1': '경제',\n",
        "      '2': '문화',\n",
        "      '3': '미용/건강',\n",
        "      '4': '사회',\n",
        "      '5': '생활',\n",
        "      '6': '스포츠',\n",
        "      '7': '연예',\n",
        "      '8': '정치'}\n",
        "\n",
        "    for key, value in label_dict.items():\n",
        "      print(value)\n",
        "      lucy_data[label_colname] = lucy_data[label_colname].str.replace(value, key)\n",
        "\n",
        "    now = int(round(time.time() * 1000))\n",
        "    filename = 'sample_' + str(now) + '.txt'\n",
        "    save_path = os.path.join(save_directory, filename)\n",
        "    lucy_data.to_csv(save_path , sep = '\\t' , index = False)\n",
        "    print(\"===============Data encoding success! please check this directory : \", save_path)\n",
        "    return save_path\n",
        "\n",
        "  #dataset 불러오기\n",
        "\n",
        "  def load_data(self, save_path, data_colnum, label_colnum):\n",
        "    \"\"\"\n",
        "      tips: 저장된 input dataset을 불러옵니다.\n",
        "      Args:\n",
        "          save_path : txt데이터의 path\n",
        "          data_colnum : data의 컬럼번호\n",
        "          label_colnum : label의 컬럼번호\n",
        "      Returns:\n",
        "          marking_set : dataframe\n",
        "    \"\"\"\n",
        "    predict_set = nlp.data.TSVDataset(save_path, field_indices=[data_colnum,label_colnum], num_discard_samples=1)\n",
        "    return predict_set\n",
        "  \n",
        "  #예측 \n",
        "  def predict_n_save_result(self, predict_set, tok, marking_set, marking_set_data_colname, save_directory, encoding_type='euc-kr'):\n",
        "    \"\"\"\n",
        "      tips: 저장된 input dataset을 불러옵니다.\n",
        "      Args:\n",
        "          predict_set : 예측할 데이터 셋\n",
        "          tok : tokenizer\n",
        "          marking_set : 기록할 데이터 셋 (dataframe)\n",
        "          marking_set_data_colname : 기록할 데이터 셋의 data 컬럼 이름\n",
        "          save_directory : 저장할 디렉토리\n",
        "          encoding_type : csv의 default는 euc-kr / 영문은 utf-8-sig \n",
        "      Returns:\n",
        "          predict_set : nlp.data.TSVDataset\n",
        "    \"\"\"\n",
        "    predict_set = BERTDataset(predict_set, 0, 1, tok, max_len, True, False)\n",
        "    predict_input = torch.utils.data.DataLoader(predict_set, batch_size=1, num_workers=9)\n",
        "    \n",
        "    #컬럼 초기화\n",
        "    marking_set['predict'] = -1\n",
        "    marking_set['predict_tag'] = 'a'\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(predict_input)):\n",
        "      token_ids = token_ids.long().to(device)\n",
        "      segment_ids = segment_ids.long().to(device)\n",
        "      valid_length= valid_length\n",
        "      out = model(token_ids, valid_length, segment_ids)\n",
        "      out_val = torch.argmax(out).cpu().numpy() # tensor > numpy로 변환\n",
        "      out_tag = ''\n",
        "      # print(marking_set[marking_set_data_colname][batch_id][1:50],'...') # 50자까지만 미리 출력 (빼도됨)\n",
        "      \n",
        "      if(out_val == 0):\n",
        "        # print('IT/과학')\n",
        "        out_tag = 'IT/과학'\n",
        "      elif(out_val == 1):\n",
        "        # print('경제')\n",
        "        out_tag = '경제'\n",
        "      elif(out_val == 2):\n",
        "        # print('문화')\n",
        "        out_tag = '문화'\n",
        "      elif(out_val == 3):\n",
        "        # print('미용/건강')\n",
        "        out_tag = '미용/건강'\n",
        "      elif(out_val == 4):\n",
        "        # print('사회')\n",
        "        out_tag = '사회'\n",
        "      elif(out_val == 5):\n",
        "        # print('생활')\n",
        "        out_tag = '생활'\n",
        "      elif(out_val == 6):\n",
        "        # print('스포츠')\n",
        "        out_tag = '스포츠'\n",
        "      elif(out_val == 7):\n",
        "        # print('연예')\n",
        "        out_tag = '연예'\n",
        "      elif(out_val == 8):\n",
        "        # print('정치')\n",
        "        out_tag = '정치'\n",
        "\n",
        "      marking_set['predict'][batch_id] = out_val\n",
        "      marking_set['predict_tag'][batch_id] = out_tag\n",
        "\n",
        "    now = int(round(time.time() * 1000))\n",
        "    filename = 'news_predict_' + str(now) + '.csv'\n",
        "    save_path = os.path.join(save_directory, filename)\n",
        "    marking_set.to_csv(save_path, encoding=encoding_type) #한글이면 euc-kr, utf-8-sig \n",
        "    print(\"===============Thank you for waiting. Predicting your dataset Finally Finish! Please Check this directory : \", save_path)\n",
        "    \n",
        "    return marking_set\n",
        "\n",
        "  #얼마나 타겟의 값을 잘 맞추었는지 평가하는 함수\n",
        "  def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "\n",
        "  #정확도 평가하는 함수\n",
        "  def get_accuracy(self, model, predict_set, tok):\n",
        "    \"\"\"\n",
        "      tips: predict_set에 대한 정확도를 평가합니다.\n",
        "      Args:\n",
        "          predict_set : 예측할 데이터 셋\n",
        "          tok : tokenizer\n",
        "          model : Pytorch Model\n",
        "    \"\"\"\n",
        "    predict_set = BERTDataset(predict_set, 0, 1, tok, self.max_len, True, False)\n",
        "    predict_input = torch.utils.data.DataLoader(predict_set, batch_size=1, num_workers=9)\n",
        "    \n",
        "    model.eval() # 평가 모드로 변경\n",
        "      \n",
        "    test_acc = 0.0\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(predict_input)):\n",
        "        token_ids = token_ids.long().to(self.device)\n",
        "        segment_ids = segment_ids.long().to(self.device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(self.device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"test accuracy : {}\".format(test_acc / (batch_id+1)))"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvhxAK3hankU"
      },
      "source": [
        "predict = NewsPredict()"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV3m2vBEauWO",
        "outputId": "7a2e0848-323f-4bdb-f8df-a84888fe2ce9"
      },
      "source": [
        "tok, model = predict.load_model_n_tokenizer('/content/drive/MyDrive/rsn_nlp_project/20210802model_95.pt')"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSBQrpPAa-xB"
      },
      "source": [
        "lucy_data = predict.preprocess_data('/content/drive/MyDrive/rsn_nlp_project/lucy_data0805_완.csv','contents')"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfdpUhuubQyT",
        "outputId": "1b1adbc6-9ef2-4a89-d5bc-daf18257edcd"
      },
      "source": [
        "save_path = predict.category_encoding_n_save(lucy_data, '/content/drive/MyDrive/rsn_nlp_project/', 'category')"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IT/과학\n",
            "경제\n",
            "문화\n",
            "미용/건강\n",
            "사회\n",
            "생활\n",
            "스포츠\n",
            "연예\n",
            "정치\n",
            "===============Data encoding success! please check this directory :  /content/drive/MyDrive/rsn_nlp_project/sample_1628155809120.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW9fD70Medij"
      },
      "source": [
        "predict_set = predict.load_data(save_path, 1,2)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307,
          "referenced_widgets": [
            "072fef589c6b49f781856246e0aabcd0",
            "88ca472fa11e4dd7bec10f9b2df6a1ce",
            "46addf17c0a94ac2815437d4532fd5ae",
            "b2c8459ee5c34afa8491b4d69c8332a4",
            "94fdb999fb4541db8466470a19cf726f",
            "5e9f158a683a4a2ab5d5d65a3903531b",
            "06de1cdafb9941f692868e6365c5f307",
            "9633c94493f64bfdb4c2ec764bd5788e"
          ]
        },
        "id": "4ARsQCt2epAN",
        "outputId": "36cb0ca9-c928-4f2b-f7fb-e0aa0102ca98"
      },
      "source": [
        "result_set = predict.predict_n_save_result(predict_set, tok, lucy_data, 'contents', '/content/drive/MyDrive/rsn_nlp_project/')"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 9 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:133: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "072fef589c6b49f781856246e0aabcd0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:171: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===============Thank you for waiting. Predicting your dataset Finally Finish! Please Check this directory :  /content/drive/MyDrive/rsn_nlp_project/news_predict_1628155965764.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "e1a81b7963c1435e8008775396983e5d",
            "4d227fdae3e74bc28c48203fa974740c",
            "247169777fbf4fbd89cb937d22c0a040",
            "d01175cfd1c249abb6a3f318e9d5d0dd",
            "69f2240572db4bceaa364a01ab373b5d",
            "c5107488c37d46579fc9f6b3a531e171",
            "d1b1f11c0e6748009b090d8daea99b0c",
            "f0fe8cc9b60a43cb800e6467612681ba"
          ]
        },
        "id": "KxshDHjBj1eO",
        "outputId": "a4411e2d-aaed-4a7b-ef01-9a8dc998420f"
      },
      "source": [
        "predict.get_accuracy(model, predict_set, tok)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 9 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:202: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1a81b7963c1435e8008775396983e5d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "test accuracy : 0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZlf9SshGiEk"
      },
      "source": [
        "{0: 'IT/과학',\n",
        " 1: '경제',\n",
        " 2: '문화',\n",
        " 3: '미용/건강',\n",
        " 4: '사회',\n",
        " 5: '생활',\n",
        " 6: '스포츠',\n",
        " 7: '연예',\n",
        " 8: '정치'}"
      ]
    }
  ]
}