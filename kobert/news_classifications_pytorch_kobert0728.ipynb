{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "colab": {
      "name": "news_classifications_pytorch_kobert.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b7b9e92b8124c61b8b07aee5664e83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c8cb77978f0498284c0e1ee711378b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3566614a26840a99dfaab41ac849c2c",
              "IPY_MODEL_3e954d90254b490eb160e18345580950"
            ]
          }
        },
        "1c8cb77978f0498284c0e1ee711378b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3566614a26840a99dfaab41ac849c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a14e79b801e450794c81b2b27a647f2",
            "_dom_classes": [],
            "description": " 60%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3214,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1926,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8593e388269143539698139fa2608ea2"
          }
        },
        "3e954d90254b490eb160e18345580950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00f1019fe00d412dbdeb964b5a6c9d81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1926/3214 [33:07&lt;22:16,  1.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afb1ff52982d4833ad1af456fd0dd975"
          }
        },
        "7a14e79b801e450794c81b2b27a647f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8593e388269143539698139fa2608ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00f1019fe00d412dbdeb964b5a6c9d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afb1ff52982d4833ad1af456fd0dd975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cateto/python4NLP/blob/main/kobert/news_classifications_pytorch_kobert0728.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVBR5c0cnKw1",
        "outputId": "13a07749-0696-4200-a5f9-e06bc2e27b6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UboVC6lIlexL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7aafa46-ecc6-47dd-fe31-645c924b1f9a"
      },
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "# 변경: 최신 버전으로 설치하면 \"Input: must be Tensor, not str\" 라는 에러 발생\n",
        "!pip install transformers==3\n",
        "!pip install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxlkZaUBlexM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7bfb13-a0a1-4df2-da5f-bdd943a504c2"
      },
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-lco_sve2\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-lco_sve2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHhi3xYGlexM"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNs6pqllexM"
      },
      "source": [
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFIVgAtilexN"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B3Rzf75lexN"
      },
      "source": [
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvuRjfPOlexN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628ca196-b423-4f56-db62-11198bd0784b"
      },
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc-_bXiblexO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "06ee4e5b-859e-4abc-bde9-789f152a4a0b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/rsn_nlp_project/sample_0728.csv')\n",
        "\n",
        "#라벨 데이터 category 정수로 변환\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(dataset['category'])\n",
        "dataset['category'] = encoder.transform(dataset['category'])\n",
        "\n",
        "# possible_labels = dataset['category'].unique()\n",
        "# label_dict = {}\n",
        "# for index, possible_label in enumerate(possible_labels):\n",
        "#     label_dict[possible_label] = index\n",
        "\n",
        "# dataset['category'] = dataset['category'].replace(label_dict)\n",
        "\n",
        "#이어서 contents 전처리(정제)\n",
        "dataset['contents'] = dataset['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\" \")\n",
        "dataset['contents'] = dataset['contents'].str.replace(\"[ ]{2,}\",\" \")\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>contents</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NIRW1900000029.1</td>\n",
              "      <td>부산 기관장들 국가사업 차질 없이 이뤄내겠다 부산 는 서병수 부산시장을 비롯한 부...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NIRW1900000029.2</td>\n",
              "      <td>새해 해돋이 명소 등 트래픽 급증 이통 사 비상태세 이상 새해를 맞이해 통화량이 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NIRW1900000029.3</td>\n",
              "      <td>조기 대선의 해 향배 가를 대 변수 는 년 정유년 대통령 선거의 해가 시작됐다 이...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NIRW1900000029.4</td>\n",
              "      <td>달라지는 소비자제도 어린이운송차 속도제한장치 의무화 올해부터는 어린이 운송용 차량...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NIRW1900000029.5</td>\n",
              "      <td>광주 간 전화 건 대선주자들의 새해 첫날 지난 한해 정치권 비리로 너무 속상한 시...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... category\n",
              "0  NIRW1900000029.1  ...        4\n",
              "1  NIRW1900000029.2  ...        0\n",
              "2  NIRW1900000029.3  ...        8\n",
              "3  NIRW1900000029.4  ...        3\n",
              "4  NIRW1900000029.5  ...        8\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOovzIvClzrL",
        "outputId": "7ee40e94-8206-42c9-a1a2-61d9da3eb848"
      },
      "source": [
        "mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
        "mapping"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'IT/과학',\n",
              " 1: '경제',\n",
              " 2: '문화',\n",
              " 3: '미용/건강',\n",
              " 4: '사회',\n",
              " 5: '생활',\n",
              " 6: '스포츠',\n",
              " 7: '연예',\n",
              " 8: '정치'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPn3sshxmmly",
        "outputId": "f5920f90-b7ed-40d0-e56b-131db9e21b7e"
      },
      "source": [
        "# test data / train data 나누기\n",
        "\n",
        "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "print(\"훈련용 data 개수:\", len(train))\n",
        "print(\"테스트용 data 개수:\", len(test))\n",
        "train.to_csv('/content/drive/MyDrive/rsn_nlp_project/sample_train.txt', sep = '\\t' , index = False)\n",
        "test.to_csv('/content/drive/MyDrive/rsn_nlp_project/sample_test.txt', sep = '\\t' , index = False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 data 개수: 102833\n",
            "테스트용 data 개수: 25709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-AsWzK1xqdT"
      },
      "source": [
        "재시도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_GIPZcM2AMC"
      },
      "source": [
        "dataset_train = nlp.data.TSVDataset(\"/content/drive/MyDrive/rsn_nlp_project/sample_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset(\"/content/drive/MyDrive/rsn_nlp_project/sample_test.txt\", field_indices=[1,2], num_discard_samples=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ov5Rsvm2Fwy",
        "outputId": "8b71475d-e6ba-434c-f3c3-5512e803107e"
      },
      "source": [
        "dataset_train[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[' 면 제주 주년 광화문 문화제 일 열려 판에 현기영 김석범 대담 업뎃 광화문 광장에서 제주 주년 국민문화제 열린다 부 잠들지 않는 노래 부 평화콘서트 진행 안치환과 자유 전인권 밴드 등 출연 에 대한 미국 책임 묻는 기자회견 예정 일 오후에는 소설가 김석범 현기영 대담 제주 주년을 맞아 주말 오후 서울 광화문 광장에서 국민문화제가 열린다 제주 제 주년 범국민위원회 범국민위 는 일 오후 시 분부터 서울 광화문 북광장에서 제주 항쟁 주년 광화문 국민문화제 를 연다고 일 밝혔다 이번 국민문화제는 희생자들 넋을 기리고 변방 에서 일어났던 을 서울에서 알리기 위한 것이다 이날 무대는 년 끝나지 않는 노래 를 주제로 부 잠들지 않는 노래 와 부 평화콘서트 로 꾸며진다 부에서는 제주어로 노래를 부르는 밴드 사우스카니발의 무대를 시작으로 이번 무대를 위해 만든 프로젝트 밴드 의 아픔을 보여주는 마임 일어나요 할망 등 다채로운 공연이 꾸려진다 또 제주의 민중가수 최상돈이 평화합창단과 함께 애기 동백꽃의 노래 와 잠들지 않는 남도 를 함께 부른다 또 명으로 구성된 프로젝트 밴드는 항쟁의 역사를 부른다 는 주제로 무대에 오르고 극단 경험과 상상은 의 도화선이 된 년 절 기념대회가 열린 제주시 관덕정 광장을 재현하는 무대를 만든다 이어 부에는 안치환과 자유 멜로망스 전인권 밴드가 출연한다 대학 재학 시절 을 소재로 한 이산하의 장편 서사시 한라산 을 읽고 잠들지 않는 남도 를 작사 작곡한 가수 안치환은 이번 콘서트에서 제주도민의 슬픔을 담담하게 표현한 신곡 월 동백 을 선보인다 청소년들의 관심을 불러일으키기 위해 인기그룹 멜로망스도 무대에 오른다 부는 년 겨울 광화문광장에서 열린 촛불문화제에서 화제를 모은 전인권 밴드가 마무리한다 식전행사로는 정오부터 제주와 서울의 인디밴드 공연 혼디 부르게 바당의 노래 가 진행된다 마로 섬 플레이버 어쩌다밴드 디오디오 묘한 정흠밴드 극도 레이지본 씨없는수박김대중 호선 버터플라이 등이 출연한다 이날 광화문광장에는 과 제주의 전통문화를 알리는 부스와 역사 관련 체험부스 등이 만들어지고 예술난장도 전국에서 모인 젊은 예술가들이 꾸린다 일 오후 시 분에는 제주 유족회와 제주 주년기념사업위원회 제주 제 주년 범국민위원회가 공동으로 학살에 대한 미국의 책임을 촉구하는 기자회견 을 열고 미국의 공식 사과와 당시 미군정과 미 군사고문단의 역할에 대한 진상조사를 촉구할 예정이다 앞서 일 오후 시 분 서울 종로구 대한민국역사박물관 층에서 일본에서 제주 의 비극을 그린 소설 화산도 를 쓴 재일동포 소설가 김석범씨와 국내에서 처음으로 을 알린 순이 삼촌 의 소설가 현기영씨가 대담하는 을 말한다 가 문학평론가 노지영씨의 사회로 열렸다 ',\n",
              "  '2'],\n",
              " [' 고령자를 노려라 은행권 모바일 실버마케팅 경쟁 후끈 은행들이 대 이상의 시니어들을 주요 타깃으로 영업력을 높이기 위한 일환으로 모바일 서비스를 잇따라 개발 출시하고 있다 쉽고 편한 모바일뱅킹 이용을 위한 서비스 개선은 물론 비금융서비스도 확대하고 있다 특히 다른 세대에 비해 많은 자산을 보유하고 있고 최근 소비주도층으로 급부상한 액티브 시니어 의 등장으로 그 동안 모바일뱅킹에서 외면받던 고령의 고객들을 유치하기 위한 경쟁이 치열해지고 있다 일 금융권에 따르면 최근 시중은행들이 대의 시니어 고객층을 위한 모바일뱅킹 앱 개발에 열을 올리고 있다 신한은행은 지난 일 대 이상 시니어 고객을 위한 모바일 앱인 미래설계 를 선보였다 이 모바일 앱은 기존 은행 앱보다 큰 글씨체와 손쉬운 화면 이동 등 사용자 중심으로 화면을 구성했다 향후 다양한 비금융 제휴를 기반으로 시니어 고객들의 관심사인 여행 건강 일자리 반려동물 정보 문화행사 초청 등 다양한 서비스를 제공하고 커뮤니티를 통해 고객들이 서로 공감하고 소통하는 라이프 플랫폼으로 만들어 나갈 예정이다 국민은행은 시니어 고객에게 특화된 서비스를 한 번에 제공하는 모바일 플랫폼 골든라이프 뱅킹 을 지난 일 출시했다 골든라이프 뱅킹은 금융서비스와 여행 쇼핑 건강 등의 비금융서비스를 복합적으로 제공하는 시니어 전용 모바일 플랫폼으로 조회 이체 메뉴 전면 배치 화면 글씨체 확대 등 시니어 맞춤형 모바일 환경을 만들어 시니어 고객이 보다 편리하게 모바일 서비스를 이용할 수 있도록 했다 기존 스타뱅킹 앱으로 접속해 간편하게 이용할 수 있다 간편 조회 이체 대표상품 소개 여행 쇼핑 건강 뷰티 여행 여가 공연 등의 맞춤형 정보를 제공하는 시니어광장 등이 있다 앞서 농협은행은 지난해 월 모바일플랫폼 올원뱅크 에서 시니어 맞춤 서비스 큰글송금 서비스 를 제공하고 있다 시니어층의 금융편의 제공을 위해 돋보기 기능을 적용한 서비스로 큰글 간편송금 기능은 물론 경조금 보내기 각종 경조사 초대장 및 감사장 보내기 기능 등을 담았다 이처럼 은행들이 시니어층을 대상으로 모바일뱅크 서비스를 확대하는 이유는 기존 대를 주타겟으로 하고 있었던 모바일뱅크의 이용 고객층을 확대하기 위한 전략이다 특히 최근에는 액티브 시니어 가 등장하면서 시니어 시장이 주목받고 있다 액티브 시니어는 경제성장의 주역으로 자산과 소득 수준이 높아 능동적인 소비주도층으로 부상한 대 세대를 지칭한다 우리나라의 경우 베이비부머 세대 년 년 출생 가 여기에 속하며 년 말 약 만명 전체 인구의 으로 집계됐다 통계청의 가계금융복지조사에 따르면 대 이상 가구주의 순자산이 전체 가구의 비중을 차지하고 있어 다른 연령층보다 구매력이 높다 김혜미 하나금융경영연구소 수석연구원은 국내에서도 경제력을 갖춘 액티브 시니어들이 금융업을 포함한 전 산업에서 주요한 소비계층으로 대두될 가능성이 높다 며 이에 대비해 은행들은 시니어 고객들을 세부 그룹별로 분류 분석하여 개별 그룹의 니즈를 반영한 차별화된 상품 및 서비스 제공이 필요하다 고 말했다 주요 영업채널이 영업점에서 모바일로 전환되는 상황에서 시니어 고객의 이탈을 막아야 할 필요도 있다 통계청과 금융감독원 한국은행이 공동 발표한 가계금융 복지조사 에 따르면 연령별 가구주의 평균 자산은 대가 억 만원으로 가장 많았으며 대 이상은 억 만원도 뒤를 이었다 이는 우리나라의 가구당 평균 자산 억 만원보다 많은 수준이다 금융자산도 대가 평균으로 만원으로 대 만원 의 두 배에 육박했다 주재승 농협은행 스마트금융부장은 국내 모바일 인구는 전 세대에 걸쳐 있음에도 모바일뱅크 서비스는 그동안 젊은층만을 대상으로 출시 경쟁을 해 왔던 측면이 있다 고 말했다 ',\n",
              "  '1'],\n",
              " [' 손보 년 콜센터 품질지수 손해보험 부문 위 선정 손해보험이 가장 우수한 콜센터 서비스를 제공하는 손보사로 선정됐다 손해보험은 일 서울 소공동 롯데호텔에서 개최되는 콜센터 품질지수 인증 수여식 에서 손해보험부문 위 기업으로 선정 우수 콜센터 인증을 받았다고 밝혔다 는 한국표준협회가 주관해 콜센터 서비스품질 수준을 과학적으로 조사 및 평가하는 모델이다 지난 개월간 총 개 기업 개 공공기관 및 지자체 콜센터를 대상으로 신뢰성 친절성 적극성 등 총 개 항목에서 평가가 진행됐다 이 조사에서 손해보험은 총점 점을 기록했으며 업계 평균 점을 상회하며 위 기업으로 선정됐다 손해보험은 년 업계 최초로 고객경험 기반의 개인맞춤형 서비스를 선보인 바 있다 고객이 일 이내 콜센터 재인입 시 상담이력을 기준으로 해당 업무의 상담원에게 연결해 불필요한 진입 과정을 최소화했다 특히 지난해 월 손보업계 최초로 보이는 를 도입해 고객이 원하는 메뉴를 쉽고 빠르게 처리할 수 있도록 하는 등 콜센터 연결과정에서의 고객 만족도를 높이고자 지속적으로 노력했다 고객이 이해하기 쉬운 용어로 메뉴명을 변경함과 동시에 이용빈도 순으로 메뉴를 재배열 및 단축시켰다 특정 고객층을 위한 별도의 서비스를 마련하기도 했다 고객 불만고객 고연령고객 등을 위한 계층별 전담 상담팀을 운영하고 청각장애인을 위한 문자서비스 외국인을 위한 계약 및 보상 관련 외국어 서비스를 제공하는 등 세심한 배려가 필요한 고객에게 맞춤형 상담 서비스를 제공해 평가단의 호평을 받기도 했다 최근 사회적으로 이슈가 되고 있는 블랙컨슈머로부터 상담원을 보호하고자 보험업계 최초로 마음이음 연결음 을 도입하고 심리상담 지원 및 휴식시간 보장 등의 직원안심제도 를 운영하는 등 직원의 심리적 부담감을 낮춰 최상의 서비스를 제공할 수 있도록 내부직원 만족도 제고에도 힘쓰고 있다 손해보험 고객부문장 전영산 상무는 타사와는 차별화된 손해보험만의 콜센터 서비스 경험을 제공하고자 노력한 것이 대외적으로 인정받게 돼 기쁘다 며 앞으로도 고객이 쉽고 빠르게 손해보험을 만날 수 있는 특별한 접점이 될 수 있도록 지속적으로 발전시켜 나가겠다 고 말했다 한편 손해보험은 콜센터 서비스의 업그레이드를 위해 새로운 디지털 기술을 접목하기도 했다 고객과의 상담내용을 문장으로 변환하는 를 통해 모든 콜을 모니터링하고 를 활용한 단순반복적인 업무 제거를 통해 고부가가치를 창출할 수 있는 전문상담원을 육성 서비스의 질이 더욱 향상될 것으로 회사는 기대하고 있다 ',\n",
              "  '1'],\n",
              " [' 신한은행 대학수학능력시험 수험생 대상 특별 이벤트 신한은행은 대학수학능력시험에 응시한 수험생들의 노력을 격려하고 수능시험 이후 새 출발을 응원하기 위한 이벤트를 일부터 년 월 일까지 실시한다고 일 밝혔다 이번 이벤트는 수능 자유 과 수능 끝 버킷 리스트 자랑 대회 그리고 공부하느라 고생 많았어 등 총 가지로 진행된다 수능 자유 는 월 일부터 년 월 일까지 입출금 통장과 체크카드를 가입한 만 세부터 만 세 수험생 중 추첨을 통해 총 명에게 아이패드 명 해피머니 상품권 명 모바일 쿠폰 명 카카오 이모티콘 명 등을 증정한다 수능 끝 버킷 리스트 자랑 대회 는 신한 홈페이지 회원 가입 후 수능이 끝나고 가장 하고 싶은 일을 댓글로 등록하면 추첨을 통해 총 명에게 치킨 기프티콘을 제공한다 공부하느라 고생 많았어 는 신한 공식 페이스북을 팔로우한 후 해당 게시물에 대학수학능력시험을 준비하느라 고생한 친구를 위한 응원 댓글을 남긴 수험생 중 추첨을 통해 총 명에게 모바일 문화상품권 만원 제공한다 신한은행 관계자는 이번 수험생 대상 이벤트를 통해 그동안 수능시험을 준비하느라 고생한 모든 수험생들이 힐링의 시간을 가졌으면 좋겠다 며 앞으로도 청년들을 위한 다양한 서비스를 출시하기 위해 노력하겠다 고 말했다 ',\n",
              "  '1'],\n",
              " [' 월 일 광주 우승팀이 갈린다 올해 프로야구 패권이 결정될지도 모를 한판승부가 펼쳐진다 호랑이와 곰 군단이 벌일 정규리그 우승 쟁탈전이다 이 경기에 따라 한국시리즈 우승컵의 주인도 가려질 수 있다 일 광주 기아 챔피언스 필드에서 열리는 두산의 타이어뱅크 리그 경기다 두 팀의 시즌 최종전이다 승 패 무로 맞선 가운데 올해 우위가 결정될 일전이다 무엇보다 올해 정규리그 우승이 여기서 결정될 가능성이 높다 일까지 위 는 두산에 경기 차 위를 달리고 있다 그러나 일 경기에서 진다면 불과 경기 차 우승을 장담하기 어렵게 된다 반대로 두산은 년 연속 직행에 대한 희망을 키울 수 있다 일 광주 대회전을 포함해 남은 경기는 가 경기 두산이 경기다 가 더 많은 경기를 남긴 만큼 더 이기면 우승을 확정할 수 있으나 두산은 띄엄띄엄 경기를 할 수 있는 유리함이 있다 강력한 선발과 불펜을 집중할 수 있기 때문이다 반면 는 이번 주말과 월 일까지 두 차례 연전이 있다 불펜이 얇은 임을 감안하면 연전은 부담이 될 수 있다 그런 면에서 두 팀의 잔여 일정 유불리는 쉽게 점치기 어렵다 때문에 일 맞대결이 중차대한 의미를 지닌다 여기서 가 이기면 정규리그 우승 가능성이 확실히 높아질 수 있다 그러나 두산이 이기면 직행 티켓의 향방은 오리무중이 된다 선발 로테이션상 외인 우완 에이스 헥터 노에시와 두산 좌완 토종 에이스 장원준이 붙을 확률이 높다 헥터는 지난 일 전 이닝 실점 쾌투로 시즌 승째 패 를 따냈다 일 동안 충분한 휴식 뒤 등판할 수 있다 헥터로서는 같은 승인 팀 동료 양현종을 제치고 다승왕에 오를 절호의 기회다 여기에 팀의 정규리그 우승이 걸린 큰 경기다 헥터의 동기 부여가 큰 상황이다 올해 헥터는 두산에 경기 승 무패 평균자책점 로 강했다 광주 홈에서는 경기 승 패 로 나쁘진 않았다 이에 맞서는 두산은 일 예정 선발 장원준이다 지난 일 전 이닝 실점 시즌 패째 승 를 안은 뒤 첫 등판이다 장원준은 올해 에 승 무패 으로 헥터 못지 않다 올해 광주 원정은 처음이나 지난해는 승 무패 로 막강했다 로서는 위 수성이 필수다 불펜이 약한 는 만에 하나라도 정규리그 우승을 뺏긴다면 후유증이 엄청나다 월 중순 이후 개월 넘게 이어온 위다 여기에 두산은 최근 년 우승을 일군 팀의 저력이 있다 정규리그 우승을 넘겨주면 올 한 해의 기세를 모두 내주게 돼 우승도 쉽지 않다 년이 마지막 우승인 는 큰 경기 경험에서 두산에 절대적으로 뒤진다 반대로 두산 역시 위 도약이 절실하다 당초 두산은 올해 우승후보 순위였다 비록 주전들의 부상과 부진 속에 전반기 부진했지만 후반기 거침없는 기세로 위까지 치고 올라왔다 위도 실패는 아니지만 위를 뺏지 못한다면 연패도 장담할 수 없다 현재 위로 위를 노리는 롯데의 기세가 무섭기 때문이다 플레이오프 에서 어떤 일이 생길지 모른다 두산은 정규리그에서 롯데와 승 패로 호각세였다 반면 위로 에 직행하면 어느 팀보다 두산이 유리하다 와 두산이 벌일 올 시즌 마지막 차전 과연 어느 팀이 정규리그 우승을 위한 교두보를 확보할 것인가 야구 팬들의 관심이 일 광주 대회전에 쏠리고 있다 ',\n",
              "  '6']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBusm-5elexO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdaf8bb7-4059-4e4d-8396-6fa16efd571e"
      },
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSLb3O3-lexO"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbrSWEd8lexO"
      },
      "source": [
        "## Setting parameters\n",
        "max_len = 163 # max_length 512, but Considering Computing Resource => set 163\n",
        "batch_size = 32 # GPU CUDA problem\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qyyVV7TlexP"
      },
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TnMhfBHwnMP",
        "outputId": "7bf0d9fc-26a2-4dad-eaa5-33b72eeed19b"
      },
      "source": [
        "data_train[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   2, 2029, 4154, 4213, 5712, 1096, 7941, 6234, 2132, 7234, 3803,\n",
              "        3358, 6060, 4805, 6896, 5049, 5561, 6951, 1316, 6557, 6333, 1633,\n",
              "        5798, 3260,    0, 1096, 7941, 6234, 1096, 7184, 4154, 4213, 5712,\n",
              "        1144, 6238, 7234, 3365, 2423, 3945, 5931, 7318, 3151, 1479, 2423,\n",
              "        4851, 7540, 4370, 3135, 7483, 7946, 5468, 3920, 4012, 7119, 5524,\n",
              "         517, 6317, 1815, 4579,  517, 6896, 1682, 2150, 4458, 2134, 5760,\n",
              "         517, 5580, 7953, 5414, 3413, 3803, 3434, 6900, 2835, 5330, 1316,\n",
              "        6557, 6333, 5049, 5561, 6951, 1633, 5798, 4154, 4213, 5712, 7088,\n",
              "        1974, 4223, 3434, 2726, 1096, 7941, 6234, 1096, 7184, 1144, 6238,\n",
              "        7234, 5330, 3365, 4154, 4128, 4213, 5712, 2318, 5507, 7054, 2318,\n",
              "        5507, 7044,  517, 5760, 3803, 3434, 2959, 2468, 6410, 2726, 1096,\n",
              "        7941, 6234, 2462, 5481, 7184, 4154, 4992, 7198, 4213, 5712, 1096,\n",
              "        7941, 6234, 1144, 6238, 7234,  517, 6116, 3332, 5782, 5439, 3803,\n",
              "        2261, 3697, 1144, 6238, 7234, 5760, 5209, 7152,  517, 5694, 7088,\n",
              "        1258, 6122, 5439, 2339, 6305,  517, 6903, 3803,    3], dtype=int32),\n",
              " array(163, dtype=int32),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoE4aDiZlexP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceeba03f-e8f2-462a-8bd8-73552788b828"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIyiQzbFlexP"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                #  num_classes=2,\n",
        "                 num_classes=9,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Qaeny3lexP"
      },
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2kyvpnqlexQ"
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcxAuw18lexQ"
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo6cWwxblexQ"
      },
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14_Uw-BjlexQ"
      },
      "source": [
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIjxwIsFlexQ"
      },
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUZ55GRDlexQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "7b7b9e92b8124c61b8b07aee5664e83c",
            "1c8cb77978f0498284c0e1ee711378b3",
            "c3566614a26840a99dfaab41ac849c2c",
            "3e954d90254b490eb160e18345580950",
            "7a14e79b801e450794c81b2b27a647f2",
            "8593e388269143539698139fa2608ea2",
            "00f1019fe00d412dbdeb964b5a6c9d81",
            "afb1ff52982d4833ad1af456fd0dd975"
          ]
        },
        "outputId": "0e4f9ead-562a-41ac-b18e-942154d0f27a"
      },
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b7b9e92b8124c61b8b07aee5664e83c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3214.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 2.258406162261963 train acc 0.09375\n",
            "epoch 1 batch id 201 loss 1.5925551652908325 train acc 0.23041044776119404\n",
            "epoch 1 batch id 401 loss 0.5791765451431274 train acc 0.45183915211970077\n",
            "epoch 1 batch id 601 loss 0.7329061627388 train acc 0.5754471713810316\n",
            "epoch 1 batch id 801 loss 0.4771496057510376 train acc 0.6419319600499376\n",
            "epoch 1 batch id 1001 loss 0.3794427514076233 train acc 0.6816933066933067\n",
            "epoch 1 batch id 1201 loss 0.5340436697006226 train acc 0.7111001248959201\n",
            "epoch 1 batch id 1401 loss 0.38508814573287964 train acc 0.7315310492505354\n",
            "epoch 1 batch id 1601 loss 0.5686830878257751 train acc 0.7470331043098064\n",
            "epoch 1 batch id 1801 loss 0.3707597553730011 train acc 0.7590574680732927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr65M3Tn4eAr"
      },
      "source": [
        "# 테스트 문장 예측\n",
        "\n",
        "test_sentence = '태권도 대표팀이 대회 마지막 날 종주국의 면모를 보였다. 비록 ‘노골드’라는 아쉬운 성적을 남겼지만 경기 종료 1초 전 ‘버저비터 발차기’로 태권도의 재미를 높였고, 암을 극복하고 메달을 따내는 ‘인간 승리’의 드라마도 만들었다. 이다빈(25·서울시청)은 27일 일본 지바 마쿠하리 메세 A홀에서 열린 2020 도쿄 올림픽 태권도 여자 67㎏초과급 준결승에서 ‘버저비터 발차기’를 선보였다. 세계랭킹 1위 비안카 워크던(영국)을 맞아 22-24로 끌려가던 이다빈은 경기 종료 직전 왼발을 들어 워크던의 얼굴에 꽂아 넣으며 3점을 따내 극적인 역전승을 일궈냈다. 대회 내내 수비 위주의 경기가 반복되며 ‘발펜싱’이라는 오명을 얻었던 태권도가 극적이고 재밌는 경기라는 점을 이다빈이 준결승에서 제대로 보여줬다.'\n",
        "test_label = '6'\n",
        "temp_set = []\n",
        "temp_set.append(test_sentence)\n",
        "temp_set.append(test_label)\n",
        "test_set = []\n",
        "test_set.append(temp_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHAG0GtR6OOY"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGbSCCm25XM3"
      },
      "source": [
        "test_set = BERTDataset(test_set, 0, 1, tok, max_len, True, False)\n",
        "test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=9)\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_input)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  print(out)\n",
        "\n",
        "  model.eval() # 평가 모드로 변경\n",
        "      \n",
        "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "      token_ids = token_ids.long().to(device)\n",
        "      segment_ids = segment_ids.long().to(device)\n",
        "      valid_length= valid_length\n",
        "      label = label.long().to(device)\n",
        "      out = model(token_ids, valid_length, segment_ids)\n",
        "      test_acc += calc_accuracy(out, label)\n",
        "  print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}